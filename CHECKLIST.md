# Fundamental
1. Debugging Transformers 
    - Tokenization (Implementing BPE)
    - Forward Pass from scratch (Inference)
    - Backpropagation from scratch (Training), Chain Rules, Auto-Diff, Indexing Errors debugging
    - Transformer Blocks (Self-Attention, Positional/Token Embeddings, Attention Optimizations like FlashAttention, Sliding Window Attention, Long Context Length like RoPe/YaRN)
    - Debugging tensor shapes -> see NanoGPT
2. Top-K/KNN 
    - Common implementation pattern of "picking the K largest items" (BoN)
    - Look at how heaps data structures can help
3. KV Cache
    - Building Matrices
4. Decoding Strategies
    - Binary Search, Backtracking, Dijkstra
    - Speculative Decoding
5. Vision Language Models (VLMs)
6. Vision Language Action Models (VLAs)

# Advanced (if time permits)
5. Basic GPU Profiling
6. Mixture of Experts