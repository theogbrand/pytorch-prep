{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7890c39c",
   "metadata": {},
   "source": [
    "Custom ReLU Backward Pass Impl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1b0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "\n",
    "# ReLU(x) = max(0, x)\n",
    "def forward(ctx,x):\n",
    "    ctx.save_for_backward(x)\n",
    "    # return torch.max(x, torch.tensor(0.0)) # scalar, broadcasts 0.0 to perform elem wise comparison\n",
    "    return torch.max(x, torch.zeros_like(x)) # auto-matches device + dtype, avoids unnecessary BT\n",
    "\n",
    "# Derivative of ReLU (local gradient): 1 if x>0, 0 if x<0. Create mask and multiply with grad_output\n",
    "def backward(ctx, grad_output):\n",
    "    input, = ctx.saved_tensors\n",
    "    grad_output = grad_output.clone()\n",
    "    return grad_output * (input > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d252c",
   "metadata": {},
   "source": [
    "# Chain Rule Conceptually:\n",
    "- when loss.backward() is called, grad_output is received. \n",
    "- So, grad_output = dLoss/d(ReLU output)\n",
    "- grad_ReLU_input (what we want to calculate, since this becomes the grad_output for the previous layer and \"back propagates\") \n",
    "    - grad_ReLU_input = dLoss/d(ReLU input) -> use this as LHS reference point\n",
    "\n",
    "- By chain rule, dLoss/d(input) = dLoss/d(ReLU output) * d(ReLU output)/d(input)\n",
    "    - we know dLoss/d(ReLU output) from grad_output, we need to calculate d(ReLU output)/d(input)\n",
    "    - d(ReLU output)/d(input) = 0 if input < 0, 1 if input > 0\n",
    "        - or derive it analytically using calculus (or handled by autodifferentiation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fca49f",
   "metadata": {},
   "source": [
    "- The local derivative is specifically the gradient of one operation (one edge) with respect to its direct inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacf1c4",
   "metadata": {},
   "source": [
    "    [x]  ← input node\n",
    "      |\n",
    "    [ReLU] ← operation (edge)\n",
    "      |\n",
    "     [y]  ← output node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c1226",
   "metadata": {},
   "source": [
    "[input] → [Linear] → [a] → [ReLU] → [b] → [Linear] → [Loss]\n",
    "\n",
    "## BackProp Sequential Process\n",
    "     \n",
    "- The point is to get the gradients at each Tensor ([a], [b], [input]). Loss is a scalar (special case), so its gradient is always 1.\n",
    "\n",
    "- We care about *dLoss/db, dLoss/da, dLoss/dinput* at every layer, these are the gradients of each tensor at every layer, want to know how much changing each parameter will change the loss\n",
    "\n",
    "   - we use the local gradients of each operation (Linear, ReLU, Linear) to calculate them\n",
    "      - Local Gradient 3 = dLoss/db\n",
    "      - Local Gradient 2 = db/da\n",
    "      - Local Gradient 1 = da/dinput\n",
    "      \n",
    "- The \"gradients\" that always pass through are dLoss/d(input of each operation) which becomes the dLoss/d(output of previous operation) for the previous layer.\n",
    "\n",
    "When `loss.backward()` is called, backprop works **layer by layer, right to left**, and the multiplication happens **incrementally**, not all at once. Remember: always pass a derivative with \"dLoss\" as numerator to the previous layer. \n",
    "\n",
    "### Step-by-Step:\n",
    "\n",
    "1. **Start**: `∂Loss/∂Loss = 1` (implicit) always.\n",
    "\n",
    "2. **Last Linear backward** (Right to Left): \n",
    "   - Receives: `grad_output = 1` (dLoss/dLoss)\n",
    "   - Computes: `local grad 3 = ∂(Loss)/∂b` -> calculus/analytical solution\n",
    "   - Returns: By chain rule, dLoss/db = dLoss/d(Loss) * d(Loss)/db `grad_input (∂Loss/∂b) = 1 × local grad 3`\n",
    "\n",
    "3. **ReLU backward** (your custom function):\n",
    "   - Receives: `grad_output = ∂Loss/∂b`\n",
    "   - Computes: `local grad 2 = ∂b/∂a`\n",
    "   - Returns: dLoss/da = dLoss/db * db/da `grad_input (∂Loss/∂a) = (∂Loss/∂b) × (∂b/∂a)`\n",
    "\n",
    "4. **First Linear backward**:\n",
    "   - Receives: `grad_output = ∂Loss/∂a`\n",
    "   - Computes: `local grad 1 = ∂a/∂input`\n",
    "   - Returns: `grad_input (∂Loss/∂input) = (∂Loss/∂a) × (∂a/∂input)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005ba39",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "## The Universal Rule\n",
    "\n",
    "At every layer/operation:\n",
    "\n",
    "```\n",
    "grad_input = grad_output × local_gradient\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **grad_output** = the gradient flowing in from the right (has `∂Loss` in numerator)\n",
    "- **local_gradient** = `∂(output)/∂(input)` for this specific operation\n",
    "- **grad_input** = the gradient you pass to the left (still has `∂Loss` in numerator)\n",
    "\n",
    "## Concrete Example from Your Graph\n",
    "\n",
    "```\n",
    "ReLU backward:\n",
    "  grad_output = ∂Loss/∂b (received from right)\n",
    "  local_gradient = ∂b/∂a (computed for ReLU)\n",
    "  grad_input = (∂Loss/∂b) × (∂b/∂a) = ∂Loss/∂a (passed left)\n",
    "```\n",
    "\n",
    "The chain rule guarantees that as long as each operation correctly computes its local gradient and does this multiplication, the gradients will flow backward correctly through the entire network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d1fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
